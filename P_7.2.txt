1. What are the three stages to build the hypotheses or model in machine learning?

Ans.
a. Model building
b. Model testing
c. Applying the model 

--------------------------------------------------------------------------------------------------------------------------

2. What is the standard approach to supervised learning?

Ans. The standard approach to supervised learning is to split the set of examples into the training set and the test. 

--------------------------------------------------------------------------------------------------------------------------

3. What is Training set and Test set?

Ans. In various areas of information science like machine learning, a set of data is used to discover the potentially predictive relationship known as Training Set. Training set is an example given to the learner, while Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of examples held back from the learner. Training set are distinct from Test set.

--------------------------------------------------------------------------------------------------------------------------

4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?

Ans. Ensemble methods combine several decision trees classifiers to produce better predictive performance than a single decision tree classifier. The main principle behind the ensemble model is that a group of weak learners come together to form a strong learner, thus increasing the accuracy of the model.

Bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.

Boosting is a machine learning ensemble meta-algorithm for primarily reducing bias, and variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones. In contrast, a strong learner is a classifier that is arbitrarily well-correlated with the true classification.

--------------------------------------------------------------------------------------------------------------------------

5. How can you avoid overfitting? 

Ans. 
a. Add more data
b. Use data augmentation
c. Use architectures that generalize well
d. Add regularization (mostly dropout, L1/L2 regularization are also possible)
e. Reduce architecture complexity.
