{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepak\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Intercept', 'C(occupation)[T.2.0]', 'C(occupation)[T.3.0]',\n",
      "       'C(occupation)[T.4.0]', 'C(occupation)[T.5.0]', 'C(occupation)[T.6.0]',\n",
      "       'C(occupation_husb)[T.2.0]', 'C(occupation_husb)[T.3.0]',\n",
      "       'C(occupation_husb)[T.4.0]', 'C(occupation_husb)[T.5.0]',\n",
      "       'C(occupation_husb)[T.6.0]', 'rate_marriage', 'age', 'yrs_married',\n",
      "       'children', 'religious', 'educ'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# create dataframes with an intercept column and dummy variables for\n",
    "# occupation and occupation_husb\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column names of X\n",
    "X = X.rename(columns = {'C(occupation)[T.2.0]':'occ_2',\n",
    "                        'C(occupation)[T.3.0]':'occ_3',\n",
    "                        'C(occupation)[T.4.0]':'occ_4',\n",
    "                        'C(occupation)[T.5.0]':'occ_5',\n",
    "                        'C(occupation)[T.6.0]':'occ_6',\n",
    "                        'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "                        'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "                        'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "                        'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "                        'C(occupation_husb)[T.6.0]':'occ_husb_6'})\n",
    "\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepak\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by splitting into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "[1. 0. 0. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Test Model and Prediction\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34198196 0.65801804]\n",
      " [0.90872783 0.09127217]\n",
      " [0.72921404 0.27078596]\n",
      " ...\n",
      " [0.77804257 0.22195743]\n",
      " [0.37310963 0.62689037]\n",
      " [0.35618029 0.64381971]]\n"
     ]
    }
   ],
   "source": [
    "# Probability\n",
    "probs = model.predict_proba(X_test)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361809045226131\n",
      "0.7472080561714708\n"
     ]
    }
   ],
   "source": [
    "# Generate evaluation metrics\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[990 110]\n",
      " [310 182]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.90      0.83      1100\n",
      "        1.0       0.62      0.37      0.46       492\n",
      "\n",
      "avg / total       0.72      0.74      0.71      1592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72100313 0.70219436 0.73824451 0.70597484 0.70597484 0.72955975\n",
      " 0.7327044  0.70440252 0.75157233 0.75      ]\n",
      "0.7241630685514876\n"
     ]
    }
   ],
   "source": [
    "# Model using 10-fold cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3224945020420987"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage had affairs\n",
    "y.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
